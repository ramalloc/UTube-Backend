-> Here we are taking images from user So we upload those images on third party Storage :- AWS or Cloudnery. But before uploading those 
    images on cloud we Store them on our server temporarly for utilising those data in case of any connection loss to send the images on 
    cloud.
-> To store temporary images on server we make a folder for that called :- {temp} which is inside of {public} folder. Now git cannot push
    the empty folders on github, So to upload the {temp} folder on server so that temporary images can be stored in the temp folder in 
    future. Therefore we make file of {.gitkeep} which is empty, It is helpful in tracking these types of Util Folders.

-> Now we will make {.gitignore} and those files which should not be upload on git. In market we habe ..gitignore generator which consists
    predefined .gitignore files according to the project/Tech Stack, like here we have-{https://mrkandreev.name/snippets/gitignore-generator/}
    We just need to copy and paste it in .gitignore file and we can add from our side as well.

-> Now we will make .env file

-> Now to organise our file we make src folder, then we make app.js, constants.js, index.js files in src.
-> After that we will make some folders in src :- 
    controller - It includes functionalities majorally, db - It consists database connectivity configurations, 
    middlewares - They are the codes which we want to run in b/w, like checking the request b/w client and server,
    models, routes, utils - It consists the repeated functions which are used consecutively / again an again in different files. 
-> When we make project with team then there is high chance that the code can show conflicts because different style of code which creates
    issue while merging the code on github. So the formatting of code should be same and consistent. Therefore we use {prettier} as library,
    the formatting can be changed as every project requirements therefore we can use prettier generator tools as well.
    After installing the prettier we have to include some files manually, First we have to make a file {.prettierrc} in src folder, It is 
    configuration file of prettier like :- comma, semicolon etc. details. Second file we make is {.prettierignore}, It consists those
    file names where we don't want to implement the prettier.




----> Database Connection
-> We will add mongodb url and other env in .env file, we don't need '/' in last of mongodb url.
-> Now we will add and export our Database name in constants.js file as DB_NAME = "UTubeDB"
-> There are two ways to connnect databse :- 1st is that we can add database connection code in index.js, so when index.js executed our
    database connection also executed.
    2nd method is we make different file for database connection code and we will import that file in index.js.
-> We need dotenv, mongoose and express, so we install it.
-> So first we will use mongoose to make connection with mongodb. 
**-> Whenever we try to communicate with database there is high chance that problems can occurs. Therefore we should wrap it in try-catch
    or in promises.
**-> "Our Database is always in other Continent", means it takes time to communicate with database therefore we use asyn-await always.

-- 1st Appraoch --
-> Here we are writing the database connection code using IIFEs - A JavaScript IIFE (Immediately Invoked Function Expression)
    is a function that runs the moment it is invoked or called in the JavaScript event loop.
-> We should always write ';' before IIFE because it is possible that previous doesn't have semicolon which may occurs error.
-> Then we wil wrap code in async and in try-catch, We have to add DB_NAME also after DB_URL/
-> Sometimes Programmers implement express in index.js file, They add listeners rigth after database connection.


-- 2nd Approach -- 
-> We make a file in db folder and implement the database connection code there, Here We will make a function and export that.
-> We are using process.exit() in error handling - Calling process.exit() will force the process to exit as quickly as possible even if 
    there are still asynchronous operations pending that have not yet completed fully, including I/O operations to process.stdout 
    and process.stderr. In most situations, it is not actually necessary to call process.exit()explicitly.
    The Node.js process will exit on its own if there is no additional work pending in the event loop.
    The process.exitCode property can be set to tell the process which exit code to use when the process exits gracefully.
-> Production, developement and testing have different databases, So {connectionInstance.connection.host} gives the name of host connected. 

-- Setting Dotenv --
-> As early as possible in your application, import and configure dotenv. We should add in index.js which loads first on server
    we should add dotenv first and configure. But dotenv adding method disrupt our consistency of importing because it uses require.
    So here we have to import it then have to configure it as well, takes path of .env file in configuration.
-> We can use import dotenv as experimental feature, we have to write some commands in "dev" packagae.json after "nodemon" to load 
    all dotenv configurations but at this time we have to load it as experimental feature.


-- Setting Express --
-> We initialize the express in app.js and export it. We import app.js in index.js, connectDB is an async function therefore it returns 
    promise. In index.js after calling connectDB() we get promise so we use then() and catch() for Immediate initialization of express/app
    listener.
-> We mainly work in express on request and response. Most used is - req.params which consists the info comes from url, 
    req.body consists data in forms or json etc, req.cookies used to store or retrieve data in user's browser used by middleware .
    So we have to install cookie-parser and cors, Whenever we use middlewares we write it's syntax as using express's app 
    {app.use(_middleware_)}.
-> After installing of cors and cookie parser we import them in app.js, Now we have to configure them after executing app.
    We can configure more in cors, it contains some options which gives contains the accessbility options. We can define origin in options
    and status as well. In origin we set .env as CORS_ORIGIN Which we have to set in .env file, We set CORS_ORIGIN = * means anyone can 
    access but we can add vercel, netlify etc as well.
-> We can get data from url, json, req-body, direct-form, json-form. So it needs some settings like limitation of incoming json data to 
    prevent from server crash. Now we can configure json with express, Common optionis {express.json({limit:"16kb"})}.
    Before express version needs middlewares like body-parser to accept can configure json data.
-> Now we have to configure the datas whose are coming from url, Express gives one more direct configuration to encode the url 
    {express.urlencoded()} it is sufficient but it also contains some option like "extended", "limit" {express.urlencoded(extended: true, limit: "16kb")}
    which is used to give objects in objects means helps in nesting of objects.
-> Another express configuration that we will use is :- static to keep/store file, images, fevicon in public as public asset anyone can 
    access them.

-> Cooie Parse helps in accessing ans setting the cookies in user's browser by server, means performing CRUD operation on user's browser's
    coockies. It also helps in to keep secure coockies in browser by server only. Now we configure the cookieParser in app.js.
    


--> middleware - the function/code which checks the request or response of client or server is called middleware. When an api hit
    it contains (err, req, res, next), Whenever we used next it means that is middleware. {next} is a flag, when middleware code segment
    completed its task then it forwards to the next middleware using {next} flag. If there is no next middleware in code segment then 
    it discard the process or done with the process. The arrangement of middleware is also important.



-- Database Wrapper --
-> we will communicate with database again and again in user's, video's controller. So we should make an utility file which contains
    wrapper. Wrapper takes function as method and peforms its operation.
-> We make a asyncHandler.js utile file. It contains a  higer order funciton which takes a function as parameter and returns function as well.
    It treats a function as higher order funciton.
-> We can implement higher order by two methods usuing async try-catch and Promises.
-> In try-catch method We take (req, res, next) as parameter, taking {next} because we can use it as middleware in future. Then we will implement try-catch.
    we handle the error by sending response as error code (if user send err code else we send customised err code ) and error message 
    using json.
-> In promise method we take the function and return it in the form of promise.


-- Error Handling --
-> When we are returning the error in response and we will send this many times. We don't have any structure or centralize standard to send 
    error. Now we want to standardize the api response and api's error as well which leads to the standard codebase.
-> So we have an error class in NodeJs, which contains some functions and constructors We can change them in different extended class.
    We make a file apiError.js in Utils Folder, We make a class ApiError which is inherited from Error class of NodeJs.
    We will take the constructor and then we will overwrite then constructor as well. Now whoever use the apiError class they have to 
    give some data which is defined in constructor. 

-- Api Response Handling -- 
-> We can trace error in NodeJs but for response we are using Express library. So we make a file to streamline the API Response.
-> We make a file apiResponse which consists class of ApiResponse. Whenever we send response we send them through this class/file.
    We set the default data in constructor that it needs like:- statusCode, message and data. We can overwrite them according to data.
    We have to set success = statusCode < 400, according to the standards.

--> Now we want that whenever there is an error occurs, the error should go throgh the apiError means we have to write middlewares.





--- Modeling ---
-> We make user and video model only because they are tightly coupled with each other oe dependent.
-> We used index in username field in user model, because if we want to make a field searchable in optimize way then we should make     
    the index: true.
-> We takes references in both models from each other.
-- Video --
-> Aggregation Pipeline framework makes the mongoose powerful for production. So we have to install this library - mongoose-aggregate-paginate-v2
-> It is A cursor based custom aggregate pagination library for Mongoose with customizable labels.
    So we will import, and initialize/use just before export. In mongoose we make many own middlewares and inject own plugins as well, 
    aggregate pipeline came after plugins. So we use the aggregate in plugin of mongoose, and after that we can perform aggregate operations
    on the Schema as well, here we used in videoSchema.plugin(aggregate).
-- User --
    -- password managing using bcrypt --
-> Now in user model we used bcrypt, bcrypt - A library to help you hash passwords, This library is made on core nodeJs.
    and bcryptJs is Optimized bcrypt in JavaScript with zero dependencies. Compatible to the C++ bcrypt binding on node.js 
    and also working in the browser. Here we will use bcrypt.
    -- session managing and data protection using jsonwebtoken -- 
-> jwt is not human readable, it make through algorithm. It encypts and injects the payloads/data in tokens.  
-> We can't do direct encryption therefore we need some middleware's hooks of mongoose, One of them is pre hook. It implement or run 
    some code just before the saving the data for encryption therefore it is called pre.
-> It take two parameters first is some event(validate, save, remove, updateOne etc) in it to occur, so here we are using for saving the data. 
    It runs just before saving the data in database.
    Second parameter is a callback function. But We can't use normal callback function here becuase in arrow function we don't have access 
    of {this} means it doesn't know the context or it cannot get access of (user) schema details. These are time taking process therefore 
    we used async here. Now we have to pass {next} flag to function because it is a  middleware and when function code will get 
    finished then in last we have to call this {next} to pass the flag ahead to other middleware. 
-> Now there we want to that when our details are saving, get the password field and encrypt it and then save it in database using bcrypt.
    We gave two parameters to bcrypt.hash - what to encrypt and round of hashing. But it can run every time whenever we made changes 
    in any field and saved the changes, it again changes the password hash. But we want when there is modificaiton in password then it 
    should save the password in database in hash form or run the Programme of bcrypt only.
    And there are two condition we want to change the password hash when it is new or it is modified.
    So we have to check that the password is modified or not using isModified() of mongoose and we pass the field as String. 
    If password modified then we will save the password changes else no.  
-> Now we have to add some methods, Here we will make a method to compare user's input password and the hash saved in database to check
    the password entered by user is right or not.
-> So we can inject methods using mongoose, it contains it's own also. But We can make custom methods and inject them using methods.
    {Schema.methods._method1_} we can add as many custom methods as we want to. we make function of that method which takes password 
    whenever it runs. We check the password comparision using bcrypt by its method {bcrypt.compare()} which takes user's password and 
    database password by {this.password} because it has also access of the fileds in database, we make this funciton async. 
    The compare method return true or false.


---> Now we implement JWT, JWt is a bearer token means whoever posses this data can have the access of data.    
-> JWT need some data to implement/initialization, and we write those data in .env file. First is access_token, in production we generate 
    complex string to save as access_token. Second is access_token_expiry which we can write as 1d means 1 day. Third is refresh_token,
    here we also keep long string. Fourth is refresh_token_expiry, it has more days/time as compare to access_token like 10d means 10days.
-> We store our refresh_token in database and not storing access_token in database. Means we our securing sessions and coockies as well.
-> We can make methods that generates accessToken and refreshToken with mongoose methods. Both are JWT, usage is different.
-> jwt has a sign method {jwt.sign()} which generates token, it take parameters - first is payload that should be in objects which contains
    data/payload like _id, email, userName etc. Now other parameters it takes access_token, and access_token_expiry in object,
    this function returns token. 
-> Now we will make method to generate refresh_token as well with same process above. It contains less information as compare to access_token
    and it's expiry is also more.



--- File upload using MULTER ---
-> We can't handle files using express or other tech stack. Morever we don't handle file on our server, We used third party services nad AWS.
-> File Handling should will not be used in every endpoints therefore we made it in Separate Utility File to reuse them. And whenever we 
    need that file we used that as middleware("Jaane se pehle mujhse milkar jaana").
-- cloudinary --
-> Here we are using Cloudinary as third party service to handle file, We also need some packages in backend - there are two opptions first
    is express-fileupload and second is Multer, we will use multer here.
-> So now we will signup on Cloudinary which gives cloud_name, api_key and api_secret which we have to add in .env file but first we have to
    install Cloudinary and then we will add keys in .env file.
-> We upload file through multer we cannot upload file using direct Cloudinary, Cloudinary is a service/sdk like aws.
-> Here we will do two tasks first is we get the file from user using multer and keep that file on our local server temporary then in 
    second step/task using Cloudinary we get the file from local storage and upload it ono server. We used both task in production grade.
-> We make a file named Cloudinary.service.js which contains file uploading code. Here our goal is to get the file from server by local path 
    through file system and upload it on Cloudinary. Also delete that file from local server after uploading the file on Cloudinary.
-> We import v2 as Cloudinary from Cloudinary then we import "fs" file system of nodeJs to get the path of file. Here in "fs" we are    
    using "unlink" - If path refers to a symbolic link, then the link is removed without affecting the file or directory to which that link
    refers. If the path refers to a file path that is not a symbolic link, the file is deleted.
-> In NodeJs File System files are linked or unlinked, When we delete a file that file got unlinked from file system but the file is saved 
    there in storage it just unlinked from the "fs".
-> Now we configured the Cloudinary in cloudinary.service.js, this configuration gives the access to file upload.
-> We will make a method that takes file path to upload file and deletes or unlink the files after uploading file from file system and 
    there can be problem in uploading therefore we will try-catch also used async. We use cloudinary upload method and pass filePath to it.
    We uploaded the file and returned the response to the user then we have to handle catch, We will delete/unlink the file from the file
    system if file not uploaded on cloudinary to prevent from malicious files on server. We used unlinkSync means this has to be done.
    then we export uploadCloudinary function.


---> Now we will use multer as middleware, we ccan use multer directly but here we are using as middleware and wherever we need file 
    uploading capabilities then we inject the multer there.
-> We saw in docs that we can store the file in two storage first is Diskstorage(Storage) and second is Memory Storage (Buffer), Here we 
    are using Diskstorage to save heavy files.
-> diskStorage has two properties - destination and filename, both posses a function which consists request from user contains json and 
    params, files which contains files from user this is the additional parameter which comes from multer, and cb which is callback function.
    In destination cb takes two parameter - 1st is error handling default is null and 2nd is folder destination which we gives our
    'public/temp' path.
    In filename we have file which consists many methods in it like - originalFilename means we save the file with the namw which user gives.
    Filename is used for naming the file due to saving the file in storage. here we used Date.now() as preSuffix with filename.
-> Now we store the multer in upload constant and export it.






